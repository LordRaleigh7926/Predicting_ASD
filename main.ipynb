{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am importing the necessary libraries. \n",
    "`pandas` will help me handle data efficiently, \n",
    "while the `sklearn` libraries will allow me to preprocess the data, \n",
    "split it into training and testing sets, and build models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am loading the dataset into a pandas DataFrame using `pd.read_csv`.\n",
    "I am also setting the \"id\" column as the index because it **uniquely** identifies each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Autism.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I am displaying the first five rows of the dataset to understand its structure.\n",
    "\n",
    "If you want to see more than first five rows then -\n",
    "\n",
    "`df.head(n)`\n",
    "\n",
    "here n is a number and this function will show the first n rows\n",
    "For example - `df.head(10)` will show first ten rows. By default the number is 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>A10_Score</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>jaundice</th>\n",
       "      <th>country_of_res</th>\n",
       "      <th>used_app_before</th>\n",
       "      <th>result</th>\n",
       "      <th>age_desc</th>\n",
       "      <th>relation</th>\n",
       "      <th>Class/ASD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>f</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>United States</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>m</td>\n",
       "      <td>Latino</td>\n",
       "      <td>no</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>m</td>\n",
       "      <td>Latino</td>\n",
       "      <td>yes</td>\n",
       "      <td>Spain</td>\n",
       "      <td>no</td>\n",
       "      <td>8</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Parent</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>f</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>United States</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  A7_Score  \\\n",
       "id                                                                         \n",
       "0          1         1         1         1         0         0         1   \n",
       "1          1         1         0         1         0         0         0   \n",
       "2          1         1         0         1         1         0         1   \n",
       "3          1         1         0         1         0         0         1   \n",
       "4          1         0         0         0         0         0         0   \n",
       "\n",
       "    A8_Score  A9_Score  A10_Score   age gender       ethnicity jaundice  \\\n",
       "id                                                                        \n",
       "0          1         0          0  26.0      f  White-European       no   \n",
       "1          1         0          1  24.0      m          Latino       no   \n",
       "2          1         1          1  27.0      m          Latino      yes   \n",
       "3          1         0          1  35.0      f  White-European       no   \n",
       "4          1         0          0  40.0      f             NaN       no   \n",
       "\n",
       "   country_of_res used_app_before  result     age_desc relation Class/ASD  \n",
       "id                                                                         \n",
       "0   United States              no       6  18 and more     Self        NO  \n",
       "1          Brazil              no       5  18 and more     Self        NO  \n",
       "2           Spain              no       8  18 and more   Parent       YES  \n",
       "3   United States              no       6  18 and more     Self        NO  \n",
       "4           Egypt              no       2  18 and more      NaN        NO  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly `df.tail()` shows the last 5 rows and giving it a number n will show last n rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am checking for any missing values in the dataset using `df.isna().sum()`. \n",
    "`isna()` will fetch me all the null value entries which will then be summed up with `sum()` to give me the number of null values in each column. \n",
    "This will help me see how many null entries exist in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1_Score            0\n",
       "A2_Score            0\n",
       "A3_Score            0\n",
       "A4_Score            0\n",
       "A5_Score            0\n",
       "A6_Score            0\n",
       "A7_Score            0\n",
       "A8_Score            0\n",
       "A9_Score            0\n",
       "A10_Score           0\n",
       "age                 2\n",
       "gender              0\n",
       "ethnicity          95\n",
       "jaundice            0\n",
       "country_of_res      0\n",
       "used_app_before     0\n",
       "result              0\n",
       "age_desc            0\n",
       "relation           95\n",
       "Class/ASD           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are missing values, I will drop rows with null values using `dropna()`. \n",
    "This ensures the data is clean and ready for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am confirming the number of non-null entries after dropping the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1_Score           609\n",
       "A2_Score           609\n",
       "A3_Score           609\n",
       "A4_Score           609\n",
       "A5_Score           609\n",
       "A6_Score           609\n",
       "A7_Score           609\n",
       "A8_Score           609\n",
       "A9_Score           609\n",
       "A10_Score          609\n",
       "age                609\n",
       "gender             609\n",
       "ethnicity          609\n",
       "jaundice           609\n",
       "country_of_res     609\n",
       "used_app_before    609\n",
       "result             609\n",
       "age_desc           609\n",
       "relation           609\n",
       "Class/ASD          609\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I want to identify which columns are of object type.\n",
    "This will help me later when I apply encoding to categorical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical data refers to variables that contain labels or names representing different categories or groups.\n",
    "Unlike numerical data, which is represented by numbers, categorical data usually consists of words, symbols, or letters.\n",
    "In our dataset, examples of categorical data include columns like \"gender,\" \"ethnicity,\" or \"jaundice.\"\n",
    "\n",
    "\n",
    "Most machine learning models, such as Logistic Regression, SVM, KNN, and others, require numerical input.\n",
    "These models can perform mathematical computations only on numbers and cannot process text-based categories directly.\n",
    "Therefore, we must convert categorical data into numerical form. This process is called encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, we use Ordinal Encoding for categorical columns like \"ethnicity,\" \"gender,\" and \"relation.\" This method assigns integer values to each category. For example, if the column \"gender\" contains the values \"Male\" and \"Female,\" they will be encoded as 0 for \"Male\" and 1 for \"Female.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1_Score       int64\n",
       "A2_Score       int64\n",
       "A3_Score       int64\n",
       "A4_Score       int64\n",
       "A5_Score       int64\n",
       "A6_Score       int64\n",
       "A7_Score       int64\n",
       "A8_Score       int64\n",
       "A9_Score       int64\n",
       "A10_Score      int64\n",
       "age          float64\n",
       "gender       float64\n",
       "ethnicity    float64\n",
       "jaundice     float64\n",
       "result         int64\n",
       "relation     float64\n",
       "Class/ASD    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_cols = df.select_dtypes('object').columns\n",
    "\n",
    "# I am checking the data types of each column after conversion to ensure the changes were applied correctly.\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am looking at the unique values in the \"ethnicity\" column to understand its categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['White-European', 'Latino', 'Others', 'Black', 'Asian',\n",
       "       'Middle Eastern ', 'Pasifika', 'South Asian', 'Hispanic',\n",
       "       'Turkish'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ethnicity\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am defining a helper function `encode()` that will convert categorical values in specific columns into numerical values.\n",
    "I will use `OrdinalEncoder` from sklearn to perform this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ordinal Encoder** is a tool that helps you do this by turning categories into numbers in a way that keeps their order. \n",
    "\n",
    "Here’s how it works:\n",
    "1. **Order Matters**: If you have categories that have a natural order (like \"small,\" \"medium,\" \"large\"), the Ordinal Encoder will assign numbers based on that order. For example:\n",
    "   - \"small\" could become 1\n",
    "   - \"medium\" could become 2\n",
    "   - \"large\" could become 3\n",
    "\n",
    "2. **Numbers Represent Order**: The numbers assigned reflect the order of the categories. So, \"medium\" being 2 means it's between \"small\" (1) and \"large\" (3).\n",
    "\n",
    "In summary, **Ordinal Encoder** helps convert categories into numbers while keeping the order of those categories in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(col):\n",
    "    for i in col:\n",
    "        encoder = OrdinalEncoder()\n",
    "        encoder.fit(df[[i]])\n",
    "        df[[i]]= encoder.transform(df[[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am applying the encode function on several columns that contain categorical values.\n",
    "These columns include details like ethnicity, gender, and the ASD classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode([\"ethnicity\", \"gender\", \"jaundice\", \"country_of_res\", \"relation\", \"Class/ASD\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the dataframe to see whether the function worked or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>A10_Score</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>jaundice</th>\n",
       "      <th>country_of_res</th>\n",
       "      <th>used_app_before</th>\n",
       "      <th>result</th>\n",
       "      <th>age_desc</th>\n",
       "      <th>relation</th>\n",
       "      <th>Class/ASD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>no</td>\n",
       "      <td>8</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>no</td>\n",
       "      <td>9</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  A7_Score  \\\n",
       "id                                                                         \n",
       "0          1         1         1         1         0         0         1   \n",
       "1          1         1         0         1         0         0         0   \n",
       "2          1         1         0         1         1         0         1   \n",
       "3          1         1         0         1         0         0         1   \n",
       "5          1         1         1         1         1         0         1   \n",
       "\n",
       "    A8_Score  A9_Score  A10_Score   age  gender  ethnicity  jaundice  \\\n",
       "id                                                                     \n",
       "0          1         0          0  26.0     0.0        9.0       0.0   \n",
       "1          1         0          1  24.0     1.0        3.0       0.0   \n",
       "2          1         1          1  27.0     1.0        3.0       1.0   \n",
       "3          1         0          1  35.0     0.0        9.0       0.0   \n",
       "5          1         1          1  36.0     1.0        5.0       1.0   \n",
       "\n",
       "    country_of_res used_app_before  result     age_desc  relation  Class/ASD  \n",
       "id                                                                            \n",
       "0             57.0              no       6  18 and more       4.0        0.0  \n",
       "1             11.0              no       5  18 and more       4.0        0.0  \n",
       "2             49.0              no       8  18 and more       2.0        1.0  \n",
       "3             57.0              no       6  18 and more       4.0        0.0  \n",
       "5             57.0              no       9  18 and more       4.0        1.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am now examining the \"age_desc\" column to see its value distribution.\n",
    "This will help me decide whether to retain or remove the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_desc\n",
       "18 and more    609\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.age_desc.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the inspection, I decided that the \"age_desc\" column is not useful for my model\n",
    "because **all of the rows have the same value for this column.**\n",
    "This does not give us any useful information to help us to predict.  \n",
    "so I will drop it using `drop()`.\n",
    "\n",
    "P.S. - \n",
    "- The `inplace=True` is important because it will directly edit the df on which we apply it to and drop the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"age_desc\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am checking how many unique countries are present in the \"country_of_res\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"country_of_res\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of unique countries is large, \n",
    "and this might not significantly affect the model, \n",
    "I will drop this column as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=\"country_of_res\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am reviewing the values in the \"used_app_before\" column to determine its usefulness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "used_app_before\n",
       "no     599\n",
       "yes     10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"used_app_before\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have decided to drop the \"used_app_before\" column since it doesn't provide much value.\n",
    "\n",
    "Having this much of inequality among \"yes\" and \"no\" will lead to model biasness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"used_app_before\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the dataframe after dropping irrelevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>A10_Score</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>jaundice</th>\n",
       "      <th>result</th>\n",
       "      <th>relation</th>\n",
       "      <th>Class/ASD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  A7_Score  \\\n",
       "id                                                                         \n",
       "0          1         1         1         1         0         0         1   \n",
       "1          1         1         0         1         0         0         0   \n",
       "2          1         1         0         1         1         0         1   \n",
       "3          1         1         0         1         0         0         1   \n",
       "5          1         1         1         1         1         0         1   \n",
       "\n",
       "    A8_Score  A9_Score  A10_Score   age  gender  ethnicity  jaundice  result  \\\n",
       "id                                                                             \n",
       "0          1         0          0  26.0     0.0        9.0       0.0       6   \n",
       "1          1         0          1  24.0     1.0        3.0       0.0       5   \n",
       "2          1         1          1  27.0     1.0        3.0       1.0       8   \n",
       "3          1         0          1  35.0     0.0        9.0       0.0       6   \n",
       "5          1         1          1  36.0     1.0        5.0       1.0       9   \n",
       "\n",
       "    relation  Class/ASD  \n",
       "id                       \n",
       "0        4.0        0.0  \n",
       "1        4.0        0.0  \n",
       "2        2.0        1.0  \n",
       "3        4.0        0.0  \n",
       "5        4.0        1.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I am splitting the data into features (X) and target labels (y). \n",
    "The target variable is \"Class/ASD\", which indicates if someone has autism or not.\n",
    "\n",
    "- I am using `train_test_split()` to divide the data into training and testing sets. \n",
    "- I will use 80% of the data for training and 20% for testing. \n",
    "- The `random_state` parameter ensures the split is reproducible.\n",
    "\n",
    "- `df.drop()` is used here as without `inplace=True` it will return the dataframe without the column specified (here the column we will predict). Hence giving us all the columns with which we will make our predictions.\n",
    "\n",
    "- Here `test_size` takes a decimal number from 0-1. 0.2 indicate the split to be 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=\"Class/ASD\"), df[\"Class/ASD\"], test_size=0.2, random_state=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the training data after the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>A10_Score</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>jaundice</th>\n",
       "      <th>result</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  A7_Score  \\\n",
       "id                                                                          \n",
       "298         1         0         0         1         0         0         1   \n",
       "41          0         0         0         0         1         1         0   \n",
       "243         0         0         1         0         1         1         0   \n",
       "653         1         1         1         1         1         1         1   \n",
       "668         1         0         0         0         0         0         1   \n",
       "\n",
       "     A8_Score  A9_Score  A10_Score   age  gender  ethnicity  jaundice  result  \\\n",
       "id                                                                              \n",
       "298         1         0          1  27.0     0.0        9.0       1.0       5   \n",
       "41          0         0          0  28.0     0.0        0.0       0.0       2   \n",
       "243         0         1          1  34.0     1.0        5.0       0.0       5   \n",
       "653         1         1          1  30.0     0.0        9.0       0.0      10   \n",
       "668         1         0          1  38.0     1.0        9.0       0.0       4   \n",
       "\n",
       "     relation  \n",
       "id             \n",
       "298       4.0  \n",
       "41        4.0  \n",
       "243       4.0  \n",
       "653       4.0  \n",
       "668       4.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am importing several machine learning models from sklearn.\n",
    "These models include \n",
    "\n",
    "- logistic regression\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Support Vector Machines (SVM) \n",
    "- Naive Bayes\n",
    "  \n",
    "I am also importing the `classification_report` to evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **K-Nearest Neighbors (KNN)**\n",
    "\n",
    "Imagine you have a group of friends, and you want to figure out what kind of ice cream they like. You could ask a few friends who are most similar to the person you’re asking. For example, if most of their closest friends like chocolate ice cream, you might guess that they like chocolate too.\n",
    "\n",
    "**How it works:** KNN looks at the closest examples (neighbors) in your data and assigns a label based on what most of those neighbors have. It’s like asking your friends what they like to decide what to give someone!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN is a simple algorithm that assigns the label of the nearest neighbors. \n",
    "I am training the model using the training data (`X_train` and `y_train`), \n",
    "then predicting labels for the test set (`X_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94        87\n",
      "         1.0       0.86      0.86      0.86        35\n",
      "\n",
      "    accuracy                           0.92       122\n",
      "   macro avg       0.90      0.90      0.90       122\n",
      "weighted avg       0.92      0.92      0.92       122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_knn = knn.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. **Support Vector Machine (SVM)**\n",
    "Think of this as drawing a line on a piece of paper to separate two groups of dots (for example, red dots and blue dots). SVM tries to draw this line (or hyperplane) in the best way possible so that the two groups are as far apart as possible. \n",
    "\n",
    "**How it works:** SVM finds the best line or boundary that keeps different groups apart. It’s good at handling lots of features and finding clear boundaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM is a powerful algorithm that tries to find the optimal hyperplane that separates different classes.\n",
    "I am training the SVM model and evaluating its performance in a similar way to KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97        87\n",
      "         1.0       1.00      0.86      0.92        35\n",
      "\n",
      "    accuracy                           0.96       122\n",
      "   macro avg       0.97      0.93      0.95       122\n",
      "weighted avg       0.96      0.96      0.96       122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_svm = svm.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. **Naive Bayes**\n",
    "Imagine you’re trying to guess if someone likes sports based on their hobbies and interests. Naive Bayes is like making a guess based on each hobby and interest independently and then combining those guesses.\n",
    "\n",
    "**How it works:** It uses probabilities to make a prediction. If someone likes to read and play soccer, Naive Bayes calculates the chance of them liking sports based on those hobbies and combines the chances to make a final guess.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "**Some Extra Info**\n",
    "\n",
    "#### **If you are in class 9, 10 and do not understand this, it is fine you can skip this extra info part. This is just to show how this model works mathematically**\n",
    "\n",
    "The Naive Bayes classifier is based on Bayes' Theorem, which is used to calculate the probability of a class given certain features. The formula for Naive Bayes is:\n",
    "\n",
    "$$P(C_k \\mid x_1, x_2, \\ldots, x_n) = \\frac{P(C_k) \\cdot P(x_1, x_2, \\ldots, x_n \\mid C_k)}{P(x_1, x_2, \\ldots, x_n)}$$\n",
    "\n",
    "Here’s what each term means:\n",
    "\n",
    "- **$P(C_k \\mid x_1, x_2, \\ldots, x_n) = \\frac{P(C_k) \\cdot P(x_1, x_2, \\ldots, x_n \\mid C_k)}{P(x_1, x_2, \\ldots, x_n)}$**: The probability of class $C_k$ given the features $x_1, x_2, \\ldots, x_n$.\n",
    "- **$P(C_k)$**: The prior probability of class $C_k$. This is how likely it is to be in class $C_k$ before considering any features.\n",
    "- **$P(x_1, x_2, \\ldots, x_n | C_k)$**: The likelihood of the features $x_1, x_2, \\ldots, x_n$ given class $C_k$. This is how likely the features are if we know the class is $C_k$.\n",
    "- **$P(x_1, x_2, \\ldots, x_n)$**: The total probability of the features $x_1, x_2, \\ldots, x_n$ across all classes. This acts as a normalizing factor.\n",
    "\n",
    "**Naive Assumption**: The “naive” part of Naive Bayes assumes that the features are independent given the class. So, instead of calculating the joint probability of all features, it simplifies to:\n",
    "\n",
    "$$P(x_1, x_2, \\ldots, x_n | C_k) = P(x_1 | C_k) \\cdot P(x_2 | C_k) \\cdot \\ldots \\cdot P(x_n | C_k)$$\n",
    "\n",
    "This simplifies the computation, making the Naive Bayes classifier efficient even with many features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes algorithm is based on applying Bayes' theorem with the assumption that features are independent.\n",
    "I am using the `GaussianNB` version here, which assumes the data follows a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99        87\n",
      "         1.0       0.97      1.00      0.99        35\n",
      "\n",
      "    accuracy                           0.99       122\n",
      "   macro avg       0.99      0.99      0.99       122\n",
      "weighted avg       0.99      0.99      0.99       122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_nb = nb.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. **Logistic Regression**\n",
    "Think of logistic regression as a way to predict whether someone will like a particular type of movie (yes or no) based on their preferences.\n",
    "\n",
    "**How it works:** It looks at different features (like how much someone likes action or comedy) and calculates the chance of them liking the movie. It’s simple and helps us understand the relationship between features and the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EVEN THOUGH THE NAME HAS REGRESSION IN IT. WE ARE USING IT AS A CLASSIFICATION MODEL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a linear model that estimates the probability that a given input belongs to a particular class.\n",
    "I am training the logistic regression model and setting `max_iter=500` to ensure the model converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        87\n",
      "         1.0       1.00      1.00      1.00        35\n",
      "\n",
      "    accuracy                           1.00       122\n",
      "   macro avg       1.00      1.00      1.00       122\n",
      "weighted avg       1.00      1.00      1.00       122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_log_reg = log_reg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary:\n",
    "- **KNN**: Guess based on the closest examples.\n",
    "- **SVM**: Draw a line to separate groups.\n",
    "- **Naive Bayes**: Use probabilities from each feature to make a prediction.\n",
    "- **Logistic Regression**: Predict a yes or no outcome based on features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **How to understand classification report -**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `classification_report` is a tool used to evaluate how well a classification model is performing. It provides several important metrics about the model’s performance. Here’s how to interpret each part of it:\n",
    "\n",
    "### 1. **Precision**\n",
    "- **What it is**: Precision measures how many of the items that the model classified as positive are actually positive.\n",
    "- **How to interpret**: If precision is 1.00 (or 100%), it means that every time the model said something was a positive class (like \"1.0\"), it was correct. If it’s lower, it means there were some mistakes.\n",
    "\n",
    "### 2. **Recall**\n",
    "- **What it is**: Recall measures how many of the actual positive items were correctly identified by the model.\n",
    "- **How to interpret**: If recall is 1.00 (or 100%), it means that the model found all the true positive items. If it’s lower, it means the model missed some positive items.\n",
    "\n",
    "### 3. **F1-Score**\n",
    "- **What it is**: The F1-Score is a combination of precision and recall. It’s the average of precision and recall, giving a single score that balances both.\n",
    "- **How to interpret**: An F1-Score of 1.00 means the model is perfect at both precision and recall. Lower scores indicate that there are trade-offs between precision and recall.\n",
    "\n",
    "### 4. **Support**\n",
    "- **What it is**: Support is the number of actual occurrences of each class in the dataset.\n",
    "- **How to interpret**: It tells you how many examples of each class were in the dataset. For example, there are 87 examples of class 0.0 and 35 examples of class 1.0.\n",
    "\n",
    "### 5. **Accuracy**\n",
    "- **What it is**: Accuracy measures how many predictions the model got right overall.\n",
    "- **How to interpret**: An accuracy of 1.00 (or 100%) means the model got all the predictions correct.\n",
    "\n",
    "### 6. **Macro Average**\n",
    "- **What it is**: Macro average calculates the precision, recall, and F1-Score by averaging them across all classes, treating each class equally.\n",
    "- **How to interpret**: This gives you an idea of the model’s performance across all classes without being affected by the number of examples in each class.\n",
    "\n",
    "### 7. **Weighted Average**\n",
    "- **What it is**: Weighted average calculates the precision, recall, and F1-Score by taking into account the number of examples in each class.\n",
    "- **How to interpret**: This provides an overall view of performance, considering how many examples are in each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually we do not get a full accuracy in a model unless the dataset is very non-complex or there is a very clear relation between the features and the thing to be predicted. Here although I have specifically choosen a dataset which is easy so we could easily get near 100% and in one case we did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was very surprised to see logistic regression get 100% accuracy. You will learn while doing other projects that it is quite a low-performing model.\n",
    "But in this case the logistic regression model has suited the dataset quite well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression got the highest accuracy followed by naive_bayes, svm and knn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can further tweak these models by changing their hyperparameters. and giving different values. I went with the default ones other than `max_iter=500` in logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters** are special settings that you choose before training a machine learning model. They help control how the model learns from the data and can affect how well it performs.\n",
    "\n",
    "**Think of it like this:**\n",
    "- **Recipe**: When you cook, you follow a recipe. The ingredients and amounts you use are like hyperparameters.\n",
    "- **Adjusting the Recipe**: Just as you might change the amount of sugar or cook time to make the dish taste better, you adjust hyperparameters to make the model perform better.\n",
    "\n",
    "**Examples:**\n",
    "- **Number of Neighbors (K)**: In K-Nearest Neighbors, you choose how many nearby points to look at to make a decision.\n",
    "- **Learning Rate**: In some models, this decides how quickly the model learns from the data.\n",
    "\n",
    "**Why They Matter:**\n",
    "- Choosing the right settings helps the model learn more accurately and make better predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
